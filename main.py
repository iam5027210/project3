from flask import Flask, render_template, Response,request, jsonify,session
from pymongo import MongoClient
import cv2
from finance_chatbot import Chatbot
import sys
from common import currTime,chat_with_openai,get_random_video
import mediapipe as mp
import numpy as np
#from face_processing import apply_filter
from datetime import datetime
import os
import time
import base64 
import atexit 
import uuid  # âœ… ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import openai
from markupsafe import Markup  # âœ… Flaskê°€ ì•„ë‹Œ markupsafeì—ì„œ ê°€ì ¸ì˜¤ê¸°
from deepface import DeepFace
from PIL import ImageFont, ImageDraw, Image
from flask_session import Session  # âœ… ì„¸ì…˜ ì €ì¥ì„ ìœ„í•œ Flask-Session ì¶”ê°€


# âœ… í•œê¸€ & ì´ëª¨í‹°ì½˜ ì§€ì›ì„ ìœ„í•œ í°íŠ¸ ì„¤ì •
FONT_PATH_HANGUL = "fonts/NanumGothicBold.ttf"  # í•œê¸€ ì§€ì› í°íŠ¸ íŒŒì¼ ê²½ë¡œ
FONT_PATH_EMOJI = "fonts/NotoColorEmoji.ttf"  # ì´ëª¨í‹°ì½˜ ì§€ì› í°íŠ¸ (WindowsëŠ” "Segoe UI Emoji")
FONT_SIZE = 60  # í°íŠ¸ í¬ê¸° ì¡°ì ˆ

# # âœ… ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# jjinchin = Chatbot(
#     assistant_id="asst_vNuhpU0xp8lfJACH4HxRsuBT",
#     thread_id="thread_fs7NSkPuhqY37W1A8cnD0RjU"
# )


# try:
#     font = ImageFont.truetype("fonts/NanumGothicBold.ttf", 40)
#     print("âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ!")
# except Exception as e:
#     print(f"âŒ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")







app = Flask(__name__)
#app.secret_key = os.urandom(24)
# âœ… ê³ ì •ëœ SECRET_KEY ì„¤ì • (ëœë¤ê°’ì´ ì•„ë‹ˆë¼, í•­ìƒ ë™ì¼í•œ ê°’ ì‚¬ìš©)
app.secret_key = "super_secret_fixed_key"


# âœ… Flask ì„¸ì…˜ ì„¤ì • (ì„œë²„ì—ì„œ ì„¸ì…˜ì„ ì €ì¥í•˜ì—¬ ìœ ì§€)
app.config["SESSION_TYPE"] = "filesystem"  # âœ… íŒŒì¼ ì‹œìŠ¤í…œì— ì„¸ì…˜ ì €ì¥
app.config["SESSION_PERMANENT"] = False  # âœ… ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì„¸ì…˜ ì‚­ì œ
app.config["SESSION_USE_SIGNER"] = True  # âœ… ì„¸ì…˜ ë°ì´í„° ì„œëª… (ë³´ì•ˆ ê°•í™”)
Session(app)  # âœ… ì„¸ì…˜ ì ìš©



# âœ… MongoDB ì—°ê²°
mongo_cluster = MongoClient("mongodb+srv://admin:admin1234@cluster0.uvix1.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0")
db = mongo_cluster["jjinchin"]  # âœ… "jjinchin" ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ
video_collection = db["videos"]  # âœ… "videos" ì»¬ë ‰ì…˜ ì„ íƒ
face_collection = db["faces"]



@app.route('/get_session_id')
def get_session_id():
    """ ê¸°ì¡´ ì„¸ì…˜ì´ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± """
    if 'session_id' in session:
        print(f"ğŸ“¢ ê¸°ì¡´ ì„¸ì…˜ ìœ ì§€: {session['session_id']}")
        return jsonify({"session_id": session['session_id']})
    
    
    
    # ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„±
    session['session_id'] = str(uuid.uuid4())
    print(f"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„±: {session['session_id']}")
    return jsonify({"session_id": session['session_id']})




# âœ… ì–¼êµ´ ë°ì´í„° ì €ì¥ ì—¬ë¶€ (ì˜ìƒì´ ëë‚˜ë©´ Falseë¡œ ì„¤ì •)
stop_saving_faces = False

@app.route('/start_saving_faces', methods=['POST'])
def start_saving_faces_api():
    """ video.htmlì—ì„œ ì–¼êµ´ ë°ì´í„° ì €ì¥ ì‹œì‘ """
    global stop_saving_faces
    stop_saving_faces = False  # âœ… ì–¼êµ´ ì €ì¥ ì‹œì‘
    print("âœ… stop_saving_faces = False")
    return jsonify({"status": "started"})

@app.route('/stop_saving_faces', methods=['POST'])
def stop_saving_faces_api():
    """ ì˜ìƒì´ ëë‚˜ê±°ë‚˜ index.htmlë¡œ ëŒì•„ì˜¤ë©´ ì–¼êµ´ ë°ì´í„° ì €ì¥ ì¤‘ì§€ """
    global stop_saving_faces
    stop_saving_faces = True  # âœ… ì €ì¥ ì¤‘ì§€
    print("ğŸ›‘ stop_saving_faces = True")
    return jsonify({"status": "stopped"})





@app.route('/')
def home():
    videos = list(video_collection.find({}, {"_id": 0}))  # MongoDBì—ì„œ title í¬í•¨í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    #print("ğŸ“¢ MongoDBì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°:", videos)  # ë””ë²„ê¹… ì¶œë ¥
    return render_template('index.html', videos=videos,messageTime=currTime())

@app.route('/video/<video_id>')
def video_page(video_id):
    # âœ… URLì—ì„œ analysis_mode ê°’ì„ ê°€ì ¸ì˜´ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ None)
    analysis_mode = request.args.get("analysis_mode", None)
    
    print(f"ğŸ“¢ ì˜ìƒ í˜ì´ì§€ ë¡œë“œë¨ - ë¶„ì„ ëª¨ë“œ: {analysis_mode}")
    return render_template('video.html', video_id=video_id, messageTime=currTime(), analysis_mode=analysis_mode)

@app.route('/chatbot_page')
def chatbot_page():
    return render_template('chatbot.html',messageTime=currTime())




@app.route('/chat-api', methods=['POST'])
def chat_api():
    global mbti_mode
    request_message = request.form.get("message")  
    analysis_mode = request.form.get("analysis_mode", request.args.get("analysis_mode", None))  # âœ… POST + GET ì§€ì› 
    print(f"ğŸ“¢ ìˆ˜ì‹ ëœ ë©”ì‹œì§€: {request_message}, í˜„ì¬ ë¶„ì„ ëª¨ë“œ: {analysis_mode}")

        # âœ… GPT ìš”ì²­ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
    if session.get("last_message") == request_message:
        print("âš  ì´ë¯¸ ê°™ì€ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ë¬´ì‹œ")
        return jsonify({"response_message": "âš  ì¤‘ë³µëœ ë©”ì‹œì§€ëŠ” ì²˜ë¦¬ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."})

    session["last_message"] = request_message  # âœ… ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì €ì¥

    try:

        # âœ… ê¸°ë³¸ì ì¸ í˜ë¥´ì†Œë‚˜ ë° ì„¤ì • (ë³€ê²½ ê°€ëŠ¥!)
        auto_prompt_cmd = {
            "ì–´íˆ¬": "ë°˜ë§ ì‚¬ìš© ê¸ˆì§€",
            "ìŠ¤íƒ€ì¼": "ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ",
            "ê¸¸ì´": "ì§§ê²Œ, 1ì¤„ë¡œ",
            "ëª©ì ": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì•Œë§ê²Œ ë‹µë³€"
        }
        
        

        if "ğŸ“¢ ë¶„ì„ ê²°ê³¼ê°€ ë‚˜ì™”ì–´ìš”!" in request_message:  # ê°€ì§œ ì±—ë´‡ ë©”ì„¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ gpt ì‘ë‹µ ë°›ê¸° (ì±—ë´‡ êµ¬í˜„ ë©”ì„¸ì§€ ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸ìš©)
            # âœ… OpenAI GPT APIë¥¼ í†µí•´ ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë©”ì‹œì§€ ìƒì„±
            generated_analysis = chat_with_openai("ì´ ì‚¬ìš©ìì˜ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ 1ì¤„,20ìì´ë‚´ë¡œ ë§í•´ì¤˜.")
            recommended_video_url = get_random_video()  # âœ… DBì—ì„œ Flask ë¼ìš°íŠ¸ í˜•ì‹ì˜ ì˜ìƒ URL ê°€ì ¸ì˜¤ê¸°
            response_message = f"ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! ì˜ìƒì„ ë‹¤ ë³´ì…¨ë„¤ìš”! ğŸ˜Š \n\n ğŸ­ **ë¶„ì„ ê²°ê³¼:** {generated_analysis} \n\n ğŸ¥ <a href='{recommended_video_url}' target='_top'>ì¶”ì²œ ì˜ìƒ ë³´ëŸ¬ ê°€ê¸°</a>"  
        
        elif analysis_mode == "mbti":
            print("ğŸ”¹ MBTI ëª¨ë“œ í™œì„±í™”ë¨ - MBTI ìŠ¤íƒ€ì¼ë¡œ GPT ì‘ë‹µ ìƒì„±")
            # âœ… MBTI ìŠ¤íƒ€ì¼ ê°ì • ë¶„ì„ ìš”ì²­
            prompt = f"""
            ì‚¬ìš©ìì˜ ê°ì • ë³€í™” ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, MBTI ìŠ¤íƒ€ì¼ ë¶„ì„ì„ í•´ì¤˜.
            ì‚¬ìš©ìì˜ ê°ì • íŒ¨í„´ì„ MBTI ìœ í˜•ì²˜ëŸ¼ ë¶„ë¥˜í•˜ê³ , ì„±ê²©ì„ í•´ì„í•´ì¤˜.
            ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. ì´ëª¨í‹°ì½˜ë„ ì ì ˆíˆ ì¶”ê°€í•˜ê³ , 1ì¤„ë¡œ 20ìì ì´ë‚´ë¡œ ì§§ê²Œ ë§Œë“¤ì–´ì¤˜!

            ê°ì • ë³€í™” ë°ì´í„°:
            {request_message}
            """
        elif analysis_mode == "character":
            print("ğŸ”¹ ì˜í™”/ê²Œì„ ìºë¦­í„° ëª¨ë“œ í™œì„±í™”ë¨")
            prompt = f"""
            ì‚¬ìš©ìì˜ ê°ì • ë³€í™”ë¥¼ ì‹¬ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì²˜ëŸ¼ ë¶„ì„í•´ì¤˜.
            ìœ í˜•ì„ ì¬ë¯¸ìˆëŠ” ë³„ëª…ì´ë‚˜ ì„±ê²© íŒ¨í„´ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ ,
            ê°ì •ì„ ë¡¤ëŸ¬ì½”ìŠ¤í„°, ê²Œì„ ìºë¦­í„°, ì ìˆ˜ ë“±ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.
            ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. ì´ëª¨í‹°ì½˜ë„ ì ì ˆíˆ ì¶”ê°€í•˜ê³ , 1ì¤„ë¡œ 20ìì ì´ë‚´ë¡œ ì§§ê²Œ ë§Œë“¤ì–´ì¤˜!

            ê°ì • ë³€í™” ë°ì´í„°:
            {request_message}
            """
        elif analysis_mode == "emotion":
            print("ğŸ”¹ ê°ì • ìœ í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”ë¨")
            prompt = f"""
            ì‚¬ìš©ìì˜ ê°ì • ë³€í™” ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì‹¬ë¦¬í…ŒìŠ¤íŠ¸ ê²°ê³¼ì²˜ëŸ¼ ë¶„ì„í•´ì¤˜.
            ì‚¬ìš©ìì˜ ê°ì • íŒ¨í„´ì„ ì¬ë¯¸ìˆëŠ” ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ê·¸ ì‚¬ëŒì˜ ì„±ê²©ì„ í•´ì„í•´ì¤˜.
            ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜. ì´ëª¨í‹°ì½˜ë„ ì ì ˆíˆ ì¶”ê°€í•˜ê³ , 1ì¤„ë¡œ 20ìì ì´ë‚´ë¡œ ì§§ê²Œ ë§Œë“¤ì–´ì¤˜!

            ê°ì • ë³€í™” ë°ì´í„°:
            {request_message}
            """

        # âœ… ì¼ë°˜ì ì¸ ë©”ì‹œì§€ ì²˜ë¦¬
        else:

            prompt = f"{request_message} ({auto_prompt_cmd})"
        
        response_message = chat_with_openai(prompt)

        print("ğŸ“¢ ì±—ë´‡ ì‘ë‹µ:", response_message)
        return jsonify({"response_message": Markup(response_message)})  # âœ… HTML íƒœê·¸ ì ìš©

    
    except Exception as e:
        print(f"âŒ `chat-api` ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"response_message": "âš  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"})


# MediaPipe ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ì´ˆê¸°í™”

mp_face_detection = mp.solutions.face_detection
mp_face_mesh = mp.solutions.face_mesh  # ì–¼êµ´ í‘œì •ì„ ìœ„í•œ ë§ˆí¬ ê°ì§€
face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)


# âœ… ì˜ì–´ ê°ì • ë¶„ì„ ê²°ê³¼ â†’ í•œê¸€ + ì´ëª¨í‹°ì½˜ ë³€í™˜
emotion_translation = {
    "angry": "í™”ë‚¨",
    "disgust": "ì—­ê²¨ì›€",
    "fear": "ë‘ë ¤ì›€",
    "happy": "ì›ƒìŒ",
    "sad": "ìŠ¬í””",
    "surprise": "ë†€ëŒ",
    "neutral": "ì¤‘ë¦½"
}



def save_face_data(original_frame,emotion, landmarks,video_id="unknown", session_id="default_session"):
    """ ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ MongoDBì™€ ë¡œì»¬ í´ë”ì— ì €ì¥ """

    global stop_saving_faces

    if stop_saving_faces:
        print("ğŸ”´ ì–¼êµ´ ì €ì¥ ì¤‘ì§€ë¨ (index.html ë˜ëŠ” ì˜ìƒ ì¢…ë£Œ)")
        return  # âœ… ì˜ìƒì´ ëë‚˜ë©´ ì €ì¥ ì¤‘ì§€

    # âœ… í˜„ì¬ ì‹œê°„ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # ì˜ˆ: 20250218_103845

    # âœ… íŒŒì¼ëª… í˜•ì‹: ì˜ìƒ ID_ì„¸ì…˜ ID_ë‚ ì§œì‹œê°„.jpg
    filename = f"{video_id}_{session_id}_{timestamp}.jpg"

    # âœ… ì €ì¥ í´ë” ì„¤ì • (faces/{video_id}/)
    save_folder = os.path.join("faces", video_id)
    os.makedirs(save_folder, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±

    # âœ… ë¡œì»¬ íŒŒì¼ ì €ì¥ ê²½ë¡œ
    save_path = os.path.join(save_folder, filename)

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ (ë¡œì»¬)
    cv2.imwrite(save_path, original_frame)
    print(f"âœ… ë¡œì»¬ í´ë”ì— ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")

    _, buffer = cv2.imencode('.jpg', original_frame)  # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
    face_image_base64 = base64.b64encode(buffer).decode('utf-8')  # Base64 ì¸ì½”ë”©

    face_data = {
        "timestamp": time.time(),  # ì €ì¥ ì‹œê°„ (Unix Timestamp)
        "video_id": video_id,
        "session_id": session_id,
        "image_filename": filename,  # âœ… ë¡œì»¬ ì €ì¥ëœ íŒŒì¼ëª… ì¶”ê°€
        "image_path": save_path,  # âœ… ë¡œì»¬ ê²½ë¡œ ì¶”ê°€
        #"original_image": face_image_base64,  # âœ… Base64 ì¸ì½”ë”©ëœ ì›ë³¸ ì´ë¯¸ì§€
        "landmarks": landmarks,  # âœ… ëœë“œë§ˆí¬ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
        "emotion" : emotion
    }

    face_collection.insert_one(face_data)  # MongoDBì— ì €ì¥
    print("âœ… ì–¼êµ´ ë°ì´í„° & ëœë“œë§ˆí¬, ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ(video.htmlì—ì„œë§Œ ì €ì¥)")





def apply_filter(frame):
    """ ì–¼êµ´ í•„í„° ì ìš© + ë°°ê²½ì„ í•˜ì–€ìƒ‰ìœ¼ë¡œ ë³€ê²½ + í‘œì • ë§ˆí¬ ì¶”ê°€ """

    global stop_saving_faces
    if stop_saving_faces:
        return frame, frame, [], "í•´ì„ ë¶ˆê°€"  # âœ… ê¸°ë³¸ê°’ ë°˜í™˜


    h, w, _ = frame.shape
    original_frame = frame.copy()  # âœ… ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥

    # âœ… 1. ë°°ê²½ì„ ì™„ì „í•œ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •
    white_background = np.ones_like(frame, dtype=np.uint8) * 255  # ì™„ì „ í°ìƒ‰ ì´ë¯¸ì§€ ìƒì„±

    # âœ… 2. ì–¼êµ´ ê°ì§€ ì‹¤í–‰
    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    landmarks_list = []
    emotion_result = "ğŸ™‚ ì¤‘ë¦½"  # ê¸°ë³¸ê°’ ì„¤ì •


    if results.detections:
        for detection in results.detections:
            bboxC = detection.location_data.relative_bounding_box
            x, y, w_box, h_box = (int(bboxC.xmin * w), int(bboxC.ymin * h), 
                                  int(bboxC.width * w), int(bboxC.height * h))

            # âœ… 3. ì–¼êµ´ ë¶€ë¶„ë§Œ ì˜ë¼ì„œ ë°°ê²½ì´ í°ìƒ‰ì¸ ì´ë¯¸ì§€ì— ë„£ê¸°
            face_roi = frame[y:y+h_box, x:x+w_box]
            white_background[y:y+h_box, x:x+w_box] = face_roi
            

            # âœ… 4. DeepFace ê°ì • ë¶„ì„ ìˆ˜í–‰, # âœ… ê°ì • ë¶„ì„ ì‹¤í–‰ (í•œê¸€ ë³€í™˜ ì ìš©)
            emotion_result = analyze_emotion_with_deepface(face_roi)

            # # âœ… ê¸€ì í¬ê¸°(Font Scale) & ìƒ‰ìƒ(BGR ê°’) ìˆ˜ì •
            # font_scale = 1.5  # ê¸€ì í¬ê¸° í‚¤ìš°ê¸°
            # font_color = (0, 166, 255)  # ê¸€ì ìƒ‰ìƒ (BGR: )
            # thickness = 3  # ê¸€ì ë‘ê»˜ ì¦ê°€

            # # âœ… 5. ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œ
            # cv2.putText(white_background, f"{emotion_result.upper()}", 
            #             (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 
            #             font_scale, font_color, thickness, cv2.LINE_AA)
            

            # # âœ… OpenCV ëŒ€ì‹  Pillowë¡œ í•œê¸€ & ì´ëª¨í‹°ì½˜ ì¶œë ¥
            frame_pil = Image.fromarray(white_background)  # OpenCV â†’ PIL ë³€í™˜
            draw = ImageDraw.Draw(frame_pil)
            font = ImageFont.truetype(FONT_PATH_HANGUL, FONT_SIZE)

            # # âœ… í•œê¸€ & ì´ëª¨í‹°ì½˜ í‘œì‹œ (í°íŠ¸ í¬ê¸° & ìƒ‰ìƒ ì¡°ì ˆ)
            draw.text((x, y - 80), emotion_result, font=font, fill=(101,31,212))  # (RGB)
            white_background = np.array(frame_pil)  # PIL â†’ OpenCV ë³€í™˜


    # âœ… 4. ì–¼êµ´ í‘œì • ê°ì§€ë¥¼ ìœ„í•œ FaceMesh ì‹¤í–‰
    mesh_results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    
    if mesh_results.multi_face_landmarks:
        for face_landmarks in mesh_results.multi_face_landmarks:
            for landmark in face_landmarks.landmark:
                x_pos, y_pos = int(landmark.x * w), int(landmark.y * h)
                
                # âœ… í‘œì • ê°ì§€ ë§ˆí¬ í‘œì‹œ (ê¸°ë³¸ì ì¸ ì )
                cv2.circle(white_background, (x_pos, y_pos), 2, (0, 255, 0), -1)  # ì´ˆë¡ìƒ‰ ì 
                
                # âœ… ëœë“œë§ˆí¬ ë°ì´í„° ì €ì¥
                landmarks_list.append({"x": landmark.x, "y": landmark.y, "z": landmark.z})

    # # âœ… ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì €ì¥ (ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§€ëŠ” í™”ë©´ê³¼ ë³„ê°œ)
    # if results.detections:
    #     save_face_data(original_frame, landmarks_list)


    return white_background, original_frame, landmarks_list,emotion_result   # âœ… ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€ ë°˜í™˜





# âœ… ì›¹ìº  í•œ ë²ˆë§Œ ì‹¤í–‰
cap = cv2.VideoCapture(0)




def generate_frames(video_id="unknown", session_id="unknown_session"):
    """ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ë°›ì•„ì™€ í•„í„° ì ìš© í›„ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜ """
    global stop_saving_faces
    #cap = cv2.VideoCapture(0)
    last_saved_time = 0 # ë§ˆì§€ë§‰ìœ¼ë¡œ ì €ì¥ëœ ì‹œê°„

    # âœ… video_idê°€ "none"ì´ë©´ ê¸°ë³¸ê°’ ì„¤ì •
    if video_id in ["none", "unknown"]:
        print("âš  `generate_frames()`ì—ì„œ video_idê°€ 'none'ìœ¼ë¡œ ê°ì§€ë¨ â†’ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •")
        video_id = "main"
    
    print(f"ğŸ“· `generate_frames()` ì‹œì‘ë¨ - video_id: {video_id}, session_id: {session_id}, {stop_saving_faces}")

   
    while True:
        success, frame = cap.read()
        if not success:
                print("âŒ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŒ")
                continue  

        # âœ… í•„í„° ì ìš© (ë°˜í™˜ê°’ ê°œìˆ˜ ê²€ì¦ ì¶”ê°€)
        filter_result = apply_filter(frame)

        if len(filter_result) != 4:
            print(f"âš  `apply_filter()`ì˜ ë°˜í™˜ê°’ ê°œìˆ˜ ì˜¤ë¥˜: {len(filter_result)}ê°œ ë°˜í™˜ë¨")
            continue  # ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬

        filtered_frame, original_frame, landmarks, emotions = filter_result  

        
        # âœ… landmarksê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸ (ì•ˆì „í•œ ì²˜ë¦¬)
        if not isinstance(landmarks, list):
            landmarks = []  # ë§Œì•½ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        # âœ… í˜„ì¬ ì‹œê°„ í™•ì¸
        current_time = time.time()



        # âœ… video_idê°€ 'unknown'ì´ë©´ ì €ì¥ âŒ (ë©”ì¸ í˜ì´ì§€ì—ì„œ ì €ì¥ ë°©ì§€)
        if not stop_saving_faces and video_id not in ( "unknown", "none","main") and (current_time - last_saved_time >= 1.0):
            save_face_data(original_frame,emotions, landmarks,video_id, session_id)  # âœ… ì €ì¥ì€ ì—¬ê¸°ì—ì„œë§Œ ì‹¤í–‰
            last_saved_time = current_time  # âœ… ë§ˆì§€ë§‰ ì €ì¥ ì‹œê°„ì„ ì—…ë°ì´íŠ¸
        elif stop_saving_faces  and video_id not in ( "unknown", "none","main"):
            pass

        # ì›¹ìº  í™”ë©´ì„ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜
        ret, buffer = cv2.imencode('.jpg', filtered_frame)
            
        if not ret:
            print("âŒ í”„ë ˆì„ ì¸ì½”ë”© ì‹¤íŒ¨")
            continue  # âœ… ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬
        
        frame = buffer.tobytes()

        yield (b'--frame\r\n'
            b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')



def analyze_emotion_with_deepface(face_roi):
    """ DeepFaceë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì •ì„ ë¶„ì„í•œ í›„ í•œê¸€ & ì´ëª¨í‹°ì½˜ ë³€í™˜ """
    try:
        analysis = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)
        dominant_emotion = analysis[0]['dominant_emotion']
        #print(f"ğŸ­ ê°ì • ë¶„ì„ ê²°ê³¼ (ì˜ì–´): {dominant_emotion}")

        # âœ… ì˜ì–´ ê°ì •ì„ í•œê¸€ + ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë³€í™˜
        translated_emotion = emotion_translation.get(dominant_emotion, "í•´ì„ ë¶ˆê°€")
        print(f"ğŸ­ ê°ì • ë¶„ì„ ê²°ê³¼ : {translated_emotion}") # í•œê¸€

        return translated_emotion
    except Exception as e:
        print(f"âš  ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
        return "í•´ì„ ë¶ˆê°€"  # âœ… ì˜¤ë¥˜ ë°œìƒ ì‹œ "í•´ì„ë¶ˆê°€" ë°˜í™˜





@app.route('/saved_faces')
def saved_faces():
    """ ì €ì¥ëœ ì–¼êµ´ ë°ì´í„° ì¡°íšŒ API """
    faces = list(face_collection.find({}, {"_id": 0}))  # ëª¨ë“  ì–¼êµ´ ë°ì´í„° ì¡°íšŒ
    return jsonify(faces)  # JSON í˜•íƒœë¡œ ë°˜í™˜


# âœ… Flask ì¢…ë£Œ ì‹œ MongoDB ì—°ê²° ë‹«ê¸° & ì¹´ë©”ë¼ í•´ì œ
@atexit.register
def close_resources():
    print("ğŸ”´ Flask ì¢…ë£Œ - MongoDB ì—°ê²° ë‹«ìŒ & ì¹´ë©”ë¼ í•´ì œ")
    cap.release()  # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œì—ë§Œ ì¹´ë©”ë¼ í•´ì œ
    mongo_cluster.close()

#@app.route('/video_feed/', defaults={'video_id': 'none', 'session_id': 'unknown_session'})    
  
@app.route('/video_feed/<video_id>/<session_id>')
def video_feed(video_id, session_id):
    """ ì˜ìƒ IDì™€ ì„¸ì…˜ IDë¥¼ ì „ë‹¬í•˜ì—¬ í”„ë ˆì„ ìƒì„± """
    print(f"ğŸ“· ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ - video_id: {video_id}, session_id: {session_id}")
    return Response(generate_frames(video_id, session_id), mimetype='multipart/x-mixed-replace; boundary=frame')
# @app.route('/video_feed')
# def video_feed():
#     return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/get_emotion_analysis/<video_id>/<session_id>')
def get_emotion_analysis(video_id, session_id):
    
    """ MongoDBì—ì„œ íŠ¹ì • ì˜ìƒ & ì„¸ì…˜ì˜ ê°ì • ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¶„ì„ """
    
    print(f"ğŸ“¢ ê°ì • ë¶„ì„ ìš”ì²­: video_id={video_id}, session_id={session_id}")
    
    # âœ… í•´ë‹¹ ì˜ìƒ & ì„¸ì…˜ì— ëŒ€í•œ ì–¼êµ´ ê°ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    face_data = list(face_collection.find(
        {"video_id": video_id, "session_id": session_id},
        {"_id": 0, "timestamp": 1, "emotion": 1}
    ))

    if not face_data:
        return jsonify({"error": "í•´ë‹¹ ì˜ìƒì˜ ê°ì • ë°ì´í„°ê°€ ì—†ìŒ"}), 404

    # âœ… ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    face_data.sort(key=lambda x: x["timestamp"])

    # âœ… ê°ì • ë³€í™” ë¶„ì„ (ì‹œê°„ìˆœ)
    emotions_over_time = [{"timestamp": entry["timestamp"], "emotion": entry["emotion"]} for entry in face_data]

    # âœ… ê°ì • ë¹„ìœ¨ ë¶„ì„
    emotion_counts = {}
    for entry in face_data:
        emotion = entry["emotion"]
        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

    total_count = sum(emotion_counts.values())
    emotion_percentages = {emotion: round((count / total_count) * 100, 2) for emotion, count in emotion_counts.items()}

    # âœ… ì¶”ì²œ ì˜ìƒ ì¶”ê°€ (ì—¬ê¸°ì„œ ì¶”ì²œ ì˜ìƒì„ ì¶”ê°€)
    recommended_video_url = get_random_video()

    # âœ… ë¶„ì„ ê²°ê³¼ ë°˜í™˜ (ì¶”ì²œ ì˜ìƒ í¬í•¨)
    return jsonify({
        "emotions_over_time": emotions_over_time,
        "emotion_percentages": emotion_percentages,
        "recommended_video_url": recommended_video_url,  # âœ… ì¶”ì²œ ì˜ìƒ URL ì¶”ê°€!
    })



if __name__ == '__main__':
    app.run(debug=True)

