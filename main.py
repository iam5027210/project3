from flask import Flask, render_template, Response,request, jsonify
from pymongo import MongoClient
import cv2
from finance_chatbot import Chatbot
import sys
from common import currTime
import mediapipe as mp
import numpy as np
#from face_processing import apply_filter
from datetime import datetime
import os

# âœ… ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
jjinchin = Chatbot(
    assistant_id="asst_vNuhpU0xp8lfJACH4HxRsuBT",
    thread_id="thread_fs7NSkPuhqY37W1A8cnD0RjU"
)



app = Flask(__name__)



# âœ… MongoDB ì—°ê²°
mongo_cluster = MongoClient("mongodb+srv://admin:admin1234@cluster0.uvix1.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0")
db = mongo_cluster["jjinchin"]  # âœ… "jjinchin" ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ
video_collection = db["videos"]  # âœ… "videos" ì»¬ë ‰ì…˜ ì„ íƒ


@app.route('/')
def home():
    videos = list(video_collection.find({}, {"_id": 0}))  # MongoDBì—ì„œ title í¬í•¨í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    #print("ğŸ“¢ MongoDBì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°:", videos)  # ë””ë²„ê¹… ì¶œë ¥
    return render_template('index.html', videos=videos,messageTime=currTime())

@app.route('/video/<video_id>')
def video_page(video_id):
    return render_template('video.html', video_id=video_id,messageTime=currTime())

@app.route('/chatbot_page')
def chatbot_page():
    return render_template('chatbot.html',messageTime=currTime())

@app.route('/chat-api', methods=['POST'])
def chat_api():
    request_message = request.form.get("message")     
    print("request_message:", request_message)
    try: 
        jjinchin.add_user_message(request_message)
        run = jjinchin.create_run()
        _, response_message = jjinchin.get_response_content(run)
        response_python_code = jjinchin.get_interpreted_code(run.id)
    except Exception as e:
        print("assistants ai error", e)
        response_message = "[Assistants API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤]"
            
    print("response_message:", response_message)
    return {"response_message": response_message, "response_python_code": response_python_code}



# MediaPipe ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ì´ˆê¸°í™”

mp_face_detection = mp.solutions.face_detection
mp_face_mesh = mp.solutions.face_mesh  # ì–¼êµ´ í‘œì •ì„ ìœ„í•œ ë§ˆí¬ ê°ì§€
face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)

def apply_filter(frame):
    """ ì–¼êµ´ í•„í„° ì ìš© + ë°°ê²½ì„ í•˜ì–€ìƒ‰ìœ¼ë¡œ ë³€ê²½ + í‘œì • ë§ˆí¬ ì¶”ê°€ """

    h, w, _ = frame.shape

    # âœ… 1. ë°°ê²½ì„ ì™„ì „í•œ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •
    white_background = np.ones_like(frame, dtype=np.uint8) * 255  # ì™„ì „ í°ìƒ‰ ì´ë¯¸ì§€ ìƒì„±

    # âœ… 2. ì–¼êµ´ ê°ì§€ ì‹¤í–‰
    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    if results.detections:
        for detection in results.detections:
            bboxC = detection.location_data.relative_bounding_box
            x, y, w_box, h_box = (int(bboxC.xmin * w), int(bboxC.ymin * h), 
                                  int(bboxC.width * w), int(bboxC.height * h))

            # âœ… 3. ì–¼êµ´ ë¶€ë¶„ë§Œ ì˜ë¼ì„œ ë°°ê²½ì´ í°ìƒ‰ì¸ ì´ë¯¸ì§€ì— ë„£ê¸°
            face_roi = frame[y:y+h_box, x:x+w_box]
            white_background[y:y+h_box, x:x+w_box] = face_roi

    # âœ… 4. ì–¼êµ´ í‘œì • ê°ì§€ë¥¼ ìœ„í•œ FaceMesh ì‹¤í–‰
    mesh_results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    
    if mesh_results.multi_face_landmarks:
        for face_landmarks in mesh_results.multi_face_landmarks:
            for landmark in face_landmarks.landmark:
                x_pos, y_pos = int(landmark.x * w), int(landmark.y * h)
                
                # âœ… í‘œì • ê°ì§€ ë§ˆí¬ í‘œì‹œ (ê¸°ë³¸ì ì¸ ì )
                cv2.circle(white_background, (x_pos, y_pos), 2, (0, 255, 0), -1)  # ì´ˆë¡ìƒ‰ ì 

    return white_background  # ìµœì¢… í•„í„° ì ìš©ëœ ì˜ìƒ ë°˜í™˜





def generate_frames():
    """ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ë°›ì•„ì™€ í•„í„° ì ìš© í›„ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜ """
    cap = cv2.VideoCapture(0)
    
    while True:
        success, frame = cap.read()
        if not success:
            break
        
        # í•„í„° ì ìš©
        frame = apply_filter(frame)

        # ì›¹ìº  í™”ë©´ì„ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜
        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')





if __name__ == '__main__':
    app.run(debug=True)

